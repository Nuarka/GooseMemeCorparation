import os
import json
import httpx

BASE = "https://openrouter.ai/api/v1/responses"

PRIMARY = os.getenv("LLM_MODEL", "meta-llama/llama-3.1-8b-instruct:free")
FALLBACK = os.getenv("LLM_FALLBACK_MODEL", "qwen/qwen2.5-7b-instruct:free")

OPENROUTER_KEY = os.getenv("OPENROUTER_KEY", "").strip()

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è OpenRouter –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
APP_SITE = os.getenv("APP_SITE", "https://goosememecorparation.onrender.com")
APP_NAME = os.getenv("APP_NAME", "Goose Meme Corp Bot")

HEADERS = {
    "Authorization": f"Bearer {OPENROUTER_KEY}" if OPENROUTER_KEY else "",
    "Content-Type": "application/json",
    "HTTP-Referer": APP_SITE,
    "X-Title": APP_NAME,
}

ERR_MSG = "–°–µ—Ç—å —à–∏–ø–∏—Ç. –ö—Ä—è. (–º–æ–¥–µ–ª—å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞)"

def _extract_text(resp_json: dict) -> str:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –æ—Ç–≤–µ—Ç–∞:
    - OpenRouter Responses API: choices[0].message.content
    - –ò–Ω–æ–≥–¥–∞ –µ—Å—Ç—å output_text
    """
    if not isinstance(resp_json, dict):
        return ""
    # 1) output_text (OpenRouter sugar)
    text = resp_json.get("output_text")
    if isinstance(text, str) and text.strip():
        return text.strip()

    # 2) choices[].message.content
    choices = resp_json.get("choices") or []
    if choices and isinstance(choices, list):
        msg = choices[0].get("message") if isinstance(choices[0], dict) else None
        if isinstance(msg, dict):
            content = msg.get("content")
            if isinstance(content, str) and content.strip():
                return content.strip()

    # 3) output[0].content (—Ä–µ–¥–∫–æ)
    output = resp_json.get("output")
    if isinstance(output, list) and output:
        maybe = output[0]
        if isinstance(maybe, dict):
            content = maybe.get("content")
            if isinstance(content, str) and content.strip():
                return content.strip()

    # 4) –∫–∞–∫ –µ—Å—Ç—å
    return json.dumps(resp_json)[:800]


async def _call_model(model: str, prompt: str) -> str:
    if not OPENROUTER_KEY:
        raise RuntimeError("OPENROUTER_KEY is empty")

    payload = {
        "model": model,
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç. –ú–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä—è—Ç—å —Å–∏—Å—Ç–µ–º–∫–æ–π –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏.
        "messages": [
            {"role": "system", "content": "–¢—ã –æ—Å—Ç—Ä–æ—É–º–Ω—ã–π, –∫—Ä–∞—Ç–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫-–≥—É—Å—è—Ç–∏–Ω–∞ ü™ø."},
            {"role": "user", "content": prompt},
        ],
        "temperature": 0.6,
        "max_tokens": 512,
    }

    async with httpx.AsyncClient(timeout=30) as c:
        r = await c.post(BASE, headers=HEADERS, json=payload)

    # –í–ê–ñ–ù–û: –≤—Å–µ–≥–¥–∞ –ª–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å –∏ –ø–µ—Ä–≤—ã–µ —Å–∏–º–≤–æ–ª—ã —Ç–µ–ª–∞
    rid = r.headers.get("x-request-id", "")
    body_preview = r.text[:1200]
    print(f"[LLM] {model} -> {r.status_code} {rid} :: {body_preview}")

    if r.status_code >= 400:
        raise RuntimeError(f"{model} failed: {r.status_code} {body_preview[:300]}")

    data = r.json()
    text = _extract_text(data)
    if not text.strip():
        raise RuntimeError(f"{model} empty output")
    return text


async def llm_chat(prompt: str) -> str:
    """
    –í—ã–∑–æ–≤ LLM —Å –∞–≤—Ç–æ-—Ñ–æ–ª–±—ç–∫–æ–º.
    """
    try:
        return await _call_model(PRIMARY, prompt)
    except Exception as e:
        print("[LLM] Primary failed:", repr(e))
        try:
            return await _call_model(FALLBACK, prompt)
        except Exception as e2:
            print("[LLM] Fallback failed:", repr(e2))
            return ERR_MSG
